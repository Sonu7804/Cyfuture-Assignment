{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CxZwBMviotK",
        "outputId": "67534ddd-8604-42b8-f283-cf86cd69f299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6fuz27XhH90",
        "outputId": "f44b66ed-3d15-4610-829a-1dd8ceabb7a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ],
      "source": [
        "pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRrxBcQPntcb",
        "outputId": "3d16f5a3-8fc3-4a03-d6a1-c8fe426eaf29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-rkwpxiwk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-rkwpxiwk\n",
            "  Resolved https://github.com/openai/whisper.git to commit dd985ac4b90cafeef8712f2998d62c59c3e62d22\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper==20240930)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803706 sha256=f52717d7f22d00f8067846aa2d1d7e1b77f536d17b295e8857866acb5d4cac4b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5bfa5fba/wheels/1f/1d/98/9583695e6695a6ac0ad42d87511097dce5ba486647dbfecb0e\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rluQ-VKhUAHG",
        "outputId": "d99a4792-9cc8-4b01-ba86-fb750db165e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub pytube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDNWk-GPUEwI",
        "outputId": "49d4cf28-a7af-49c4-ea54-778a351b3425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pytube\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkXMngY9jtSS",
        "outputId": "6775f2eb-c864-4e94-a705-b0e44bf571a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the path of the audio file: /content/audio1.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 2.88G/2.88G [01:05<00:00, 47.1MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Hindi\n",
            "[00:00.000 --> 00:03.000]  Hello\n",
            "[00:03.000 --> 00:10.000]  Hello, I am from Department of Administrative Reforms and Public Revenues, Mahita from New Delhi.\n",
            "[00:10.000 --> 00:13.000]  I am talking to Mr. Jayjit Ikar.\n",
            "[00:13.000 --> 00:15.000]  Yes, tell me.\n",
            "[00:15.000 --> 00:23.000]  Mr. Jayjit, you lost your grievance to Department of Financial Services regarding Reserve Bank of India on 7th November, 2013.\n",
            "[00:23.000 --> 00:31.000]  Your grievance number 0076180. A survey has been called to know your satisfaction level.\n",
            "[00:31.000 --> 00:36.000]  Sir, have you checked the answer given to you by the Department?\n",
            "[00:36.000 --> 00:39.000]  No, I didn't understand.\n",
            "[00:39.000 --> 00:43.000]  Sir, you raised your grievance and filed a complaint to the Department.\n",
            "[00:43.000 --> 00:44.000]  Yes.\n",
            "[00:44.000 --> 00:50.000]  You wrote that you get a call from an unknown number and OTP is asked.\n",
            "[00:50.000 --> 00:52.000]  Yes, sir, I get a lot.\n",
            "[00:52.000 --> 00:53.000]  Yes, sir, I get a lot.\n",
            "[00:53.000 --> 00:55.000]  I get a lot of spam calls.\n",
            "[00:55.000 --> 00:56.000]  Yes, sir.\n",
            "[00:56.000 --> 00:58.000]  So, you were called regarding this.\n",
            "[00:58.000 --> 01:00.000]  Sir, you were given the answer from the Department.\n",
            "[01:00.000 --> 01:06.000]  They said that the information given to you regarding your complaint is enough.\n",
            "[01:06.000 --> 01:08.000]  You have not given enough information.\n",
            "[01:08.000 --> 01:10.000]  Because of which, the case is not being filed.\n",
            "[01:10.000 --> 01:13.000]  So, you have to file a complaint and that is it.\n",
            "[01:13.000 --> 01:19.000]  You have to mention the name of your bank in the details of the complaint.\n",
            "[01:19.000 --> 01:22.000]  You have to mention the number from which the call is coming.\n",
            "[01:22.000 --> 01:25.000]  So that the case can be filed properly.\n",
            "[01:25.000 --> 01:26.000]  Ok, ok.\n",
            "[01:26.000 --> 01:29.000]  Sir, you have called from the city, right?\n",
            "[01:29.000 --> 01:30.000]  Yes, sir.\n",
            "[01:30.000 --> 01:35.000]  Sir, I have to complain about one more thing.\n",
            "[01:35.000 --> 01:36.000]  Yes.\n",
            "[01:36.000 --> 01:38.000]  Sir, there is a lack of network in our village.\n",
            "[01:38.000 --> 01:39.000]  Can anything be done in that?\n",
            "[01:39.000 --> 01:40.000]  Yes, absolutely, sir.\n",
            "[01:40.000 --> 01:41.000]  You can do it.\n",
            "[01:41.000 --> 01:44.000]  For that, you can file a complaint in the Department of Telecommunication.\n",
            "[01:44.000 --> 01:46.000]  If there is a network issue.\n",
            "[01:46.000 --> 01:48.000]  That means, it is too much.\n",
            "[01:48.000 --> 01:49.000]  Yes, absolutely.\n",
            "[01:49.000 --> 01:50.000]  You can file a complaint.\n",
            "[01:50.000 --> 01:51.000]  Sir, here, the common people are not able to do it.\n",
            "[01:51.000 --> 01:58.000]  Sir, here, the problem related to the common people can be lodged in the agreement.\n",
            "[01:58.000 --> 02:01.000]  So, sir, will this be done or not?\n",
            "[02:01.000 --> 02:02.000]  Absolutely, sir.\n",
            "[02:02.000 --> 02:03.000]  It will be done.\n",
            "[02:03.000 --> 02:04.000]  And you have to give a proper resolution.\n",
            "[02:04.000 --> 02:08.000]  It can be that, sir, you have to give the details of the complaint properly.\n",
            "[02:08.000 --> 02:11.000]  So that it can be done.\n",
            "[02:11.000 --> 02:12.000]  Yes, sir.\n",
            "[02:12.000 --> 02:13.000]  Absolutely.\n",
            "[02:13.000 --> 02:14.000]  There will be no problem in the investigation.\n",
            "[02:14.000 --> 02:16.000]  Like, the complaint you gave is incomplete information.\n",
            "[02:16.000 --> 02:18.000]  So, there is no way to do the investigation.\n",
            "[02:18.000 --> 02:19.000]  Ok, sir.\n",
            "[02:19.000 --> 02:20.000]  It is difficult.\n",
            "[02:20.000 --> 02:22.000]  But, the department has said that you have to give the full details.\n",
            "[02:22.000 --> 02:24.000]  Like, you have to give the details of your bank.\n",
            "[02:24.000 --> 02:30.000]  And you have to mention the number from which you are getting the call regarding this.\n",
            "[02:30.000 --> 02:34.000]  And your number is also done properly.\n",
            "[02:34.000 --> 02:36.000]  Ok, sir.\n",
            "[02:36.000 --> 02:37.000]  Yes, sir.\n",
            "[02:37.000 --> 02:39.000]  So, are you satisfied with the answer, sir?\n",
            "[02:39.000 --> 02:40.000]  The answer which you have given.\n",
            "[02:40.000 --> 02:41.000]  Yes, sir.\n",
            "[02:41.000 --> 02:42.000]  Yes, sir.\n",
            "[02:42.000 --> 02:43.000]  Are you satisfied with the answer?\n",
            "[02:43.000 --> 02:44.000]  Are you satisfied with the answer?\n",
            "[02:44.000 --> 02:45.000]  Yes, sir.\n",
            "[02:45.000 --> 02:46.000]  Ok.\n",
            "[02:46.000 --> 02:47.000]  So, what should the department do in this case?\n",
            "[02:47.000 --> 02:48.000]  The response which you have given in the out of file.\n",
            "[02:48.000 --> 02:49.000]  Yes, sir.\n",
            "[02:49.000 --> 02:50.000]  In the out of file?\n",
            "[02:50.000 --> 02:51.000]  In the out of file, sir.\n",
            "[02:51.000 --> 02:52.000]  Sir, I did not get it, sir.\n",
            "[02:52.000 --> 02:53.000]  I liked it.\n",
            "[02:53.000 --> 02:54.000]  I talked to them.\n",
            "[02:54.000 --> 02:55.000]  Yes, sir.\n",
            "[02:55.000 --> 02:56.000]  Thank you very much, sir, for giving the full rating.\n",
            "[02:56.000 --> 02:57.000]  Sir, in the future, the department is giving the full rating to the department.\n",
            "[02:57.000 --> 02:58.000]  And the full effort will be made to make our service better.\n",
            "[02:58.000 --> 02:59.000]  Yes, sir.\n",
            "[02:59.000 --> 03:00.000]  Thank you, sir.\n",
            "[03:00.000 --> 03:01.000]  Yes, sir.\n",
            "[03:01.000 --> 03:02.000]  Thank you very much for giving your time.\n",
            "[03:02.000 --> 03:03.000]  Your day is good.\n",
            "[03:03.000 --> 03:04.000]  Thank you, sir.\n",
            "[03:04.000 --> 03:05.000]  Thank you.\n",
            "[03:05.000 --> 03:06.000]  You are welcome.\n",
            "Transcription for /content/audio1.wav:  Hello Hello, I am from Department of Administrative Reforms and Public Revenues, Mahita from New Delhi. I am talking to Mr. Jayjit Ikar. Yes, tell me. Mr. Jayjit, you lost your grievance to Department of Financial Services regarding Reserve Bank of India on 7th November, 2013. Your grievance number 0076180. A survey has been called to know your satisfaction level. Sir, have you checked the answer given to you by the Department? No, I didn't understand. Sir, you raised your grievance and filed a complaint to the Department. Yes. You wrote that you get a call from an unknown number and OTP is asked. Yes, sir, I get a lot. Yes, sir, I get a lot. I get a lot of spam calls. Yes, sir. So, you were called regarding this. Sir, you were given the answer from the Department. They said that the information given to you regarding your complaint is enough. You have not given enough information. Because of which, the case is not being filed. So, you have to file a complaint and that is it. You have to mention the name of your bank in the details of the complaint. You have to mention the number from which the call is coming. So that the case can be filed properly. Ok, ok. Sir, you have called from the city, right? Yes, sir. Sir, I have to complain about one more thing. Yes. Sir, there is a lack of network in our village. Can anything be done in that? Yes, absolutely, sir. You can do it. For that, you can file a complaint in the Department of Telecommunication. If there is a network issue. That means, it is too much. Yes, absolutely. You can file a complaint. Sir, here, the common people are not able to do it. Sir, here, the problem related to the common people can be lodged in the agreement. So, sir, will this be done or not? Absolutely, sir. It will be done. And you have to give a proper resolution. It can be that, sir, you have to give the details of the complaint properly. So that it can be done. Yes, sir. Absolutely. There will be no problem in the investigation. Like, the complaint you gave is incomplete information. So, there is no way to do the investigation. Ok, sir. It is difficult. But, the department has said that you have to give the full details. Like, you have to give the details of your bank. And you have to mention the number from which you are getting the call regarding this. And your number is also done properly. Ok, sir. Yes, sir. So, are you satisfied with the answer, sir? The answer which you have given. Yes, sir. Yes, sir. Are you satisfied with the answer? Are you satisfied with the answer? Yes, sir. Ok. So, what should the department do in this case? The response which you have given in the out of file. Yes, sir. In the out of file? In the out of file, sir. Sir, I did not get it, sir. I liked it. I talked to them. Yes, sir. Thank you very much, sir, for giving the full rating. Sir, in the future, the department is giving the full rating to the department. And the full effort will be made to make our service better. Yes, sir. Thank you, sir. Yes, sir. Thank you very much for giving your time. Your day is good. Thank you, sir. Thank you. You are welcome.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import whisper\n",
        "from pydub import AudioSegment\n",
        "from pytube import YouTube\n",
        "import os\n",
        "\n",
        "def convert_to_wav(audio_file):\n",
        "    # Convert audio file to WAV format\n",
        "    sound = AudioSegment.from_file(audio_file)\n",
        "    wav_file = os.path.splitext(audio_file)[0] + \".wav\"\n",
        "    sound.export(wav_file, format=\"wav\")\n",
        "    return wav_file\n",
        "\n",
        "def transcribe_audio_to_english(audio_file):\n",
        "    try:\n",
        "        model = whisper.load_model(\"large-v3\")\n",
        "        result = model.transcribe(audio_file, fp16=False, task='translate', verbose=True)\n",
        "        return result[\"text\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing {audio_file}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    audio_file = input(\"Enter the path of the audio file: \")\n",
        "\n",
        "\n",
        "    if os.path.exists(audio_file):\n",
        "        if audio_file.lower().endswith(('.mp3', '.wav', '.ogg')):\n",
        "            if audio_file.lower().endswith('.mp3'):\n",
        "                audio_file = convert_to_wav(audio_file)\n",
        "            transcription = transcribe_audio_to_english(audio_file)\n",
        "            if transcription:\n",
        "                print(f\"Transcription for {audio_file}: {transcription}\")\n",
        "            else:\n",
        "                print(f\"Failed to transcribe {audio_file}.\")\n",
        "            if audio_file.lower().endswith('.wav'):\n",
        "                os.remove(audio_file)  # Remove temporary WAV file\n",
        "        else:\n",
        "            print(f\"Unsupported audio format: {audio_file}\")\n",
        "    else:\n",
        "        print(\"File not found. Please provide a valid file path.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJ78vc8QNZpV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
